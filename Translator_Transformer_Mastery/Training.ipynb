{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C34mZg6QQj_7"
   },
   "source": [
    "# Library and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688841216427,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "bWJl0OFAQU77"
   },
   "outputs": [],
   "source": [
    "# For Colab. Run this after run time reset\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/Colab Notebooks/transformer_mastery')\n",
    "# path = '/content/drive/MyDrive/Colab Notebooks/transformer_mastery/metadata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16343,
     "status": "ok",
     "timestamp": 1688841232769,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "s3m9fRmqRRYS",
    "outputId": "3fb4b690-61b9-47a9-a137-954700908c15"
   },
   "outputs": [],
   "source": [
    "# %pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9522,
     "status": "ok",
     "timestamp": 1688841242289,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "0ruXCtF4_gCX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow import data, train, math, reduce_sum, cast, equal\n",
    "from tensorflow import argmax, float32, GradientTape, function\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from transformer import TransformerModel\n",
    "from prepare_dataset import PrepareDataset\n",
    "from time import time\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2147,
     "status": "ok",
     "timestamp": 1688841244433,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "wWAyan4lAvnX",
    "outputId": "be000dfa-4950-494f-c8da-9156947cca16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size\n",
      "9 7 3157 2009\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "dataset = PrepareDataset()\n",
    "trainX, trainY, valX, valY, train_org, val_org, enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size = dataset(\"None\")\n",
    "print('enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size')\n",
    "print(enc_seq_length, dec_seq_length, enc_vocab_size, dec_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgLG0fZRRESa"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688841242289,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "OAnqxl42ArjA"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "h = 8\n",
    "d_k = 64\n",
    "d_v = 64\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n = 6\n",
    "\n",
    "#\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.98\n",
    "epsilon = 1e-9\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688841244433,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "lZbWA5dLB5CA"
   },
   "outputs": [],
   "source": [
    "# Prepare the batches\n",
    "train_dataset = data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = data.Dataset.from_tensor_slices((valX, valY))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688841244434,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "D0TZGzsqCGZH"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fcn(target, prediction):\n",
    "    padding_mask = math.logical_not(equal(target, 0))\n",
    "    padding_mask = cast(padding_mask, float32)\n",
    "    #\n",
    "    loss = sparse_categorical_crossentropy(target, prediction)\n",
    "    #\n",
    "    return reduce_sum(loss) / reduce_sum(padding_mask)\n",
    "\n",
    "\n",
    "def accuracy_fcn(target, prediction):\n",
    "    padding_mask = math.logical_not(equal(target, 0))\n",
    "    #\n",
    "    accuracy = equal(target, argmax(prediction, axis=2))\n",
    "    accuracy = math.logical_and(padding_mask, accuracy)\n",
    "    #\n",
    "    accuracy = cast(accuracy, float32)\n",
    "    padding_mask = cast(padding_mask, float32)\n",
    "    #\n",
    "\n",
    "    return reduce_sum(accuracy) / reduce_sum(padding_mask)\n",
    "\n",
    "\n",
    "train_loss = Mean(name='train_loss')\n",
    "train_accuracy = Mean(name='train_accuracy')\n",
    "val_loss = Mean(name='val_loss')\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "class LRScheduler(LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
    "        super(LRScheduler, self).__init__(**kwargs)\n",
    "        self.d_model = cast(d_model, float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        step_num = cast(step_num, float32)\n",
    "        arg1 = step_num ** -0.5\n",
    "        arg2 = step_num * (self.warmup_steps ** -1.5)\n",
    "        return (self.d_model ** -0.5) * math.minimum(arg1, arg2)\n",
    "\n",
    "#\n",
    "optimizer = Adam(LRScheduler(d_model), beta_1, beta_2, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 37759,
     "status": "ok",
     "timestamp": 1688841282191,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "TqeS8-74RDey"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
    "                                  dec_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "\n",
    "# Checkpoint manage\n",
    "ckpt = train.Checkpoint(model=training_model, optimizer=optimizer)\n",
    "ckpt_manager = train.CheckpointManager(ckpt, './metadata/checkpoints', max_to_keep=3)\n",
    "train_loss_dict = {}\n",
    "val_loss_dict = {}\n",
    "\n",
    "\n",
    "@function\n",
    "def train_step(encoder_input, decoder_input, decoder_output):\n",
    "    with GradientTape() as tape:\n",
    "        prediction = training_model(\n",
    "            encoder_input, decoder_input, training=True)\n",
    "        loss = loss_fcn(decoder_output, prediction)\n",
    "        accuracy = accuracy_fcn(decoder_output, prediction)\n",
    "    #\n",
    "    gradients = tape.gradient(loss, training_model.trainable_weights)\n",
    "    #\n",
    "    optimizer.apply_gradients(zip(gradients, training_model.trainable_weights))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy)\n",
    "    # print(f'Loss {train_loss.result():.4f}, Accuracy {train_accuracy.result():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8264629,
     "status": "ok",
     "timestamp": 1688849546818,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "_E4tBOPLCQtH",
    "outputId": "80bd81a1-8963-41fa-ff7d-91d3a57075b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "time() = 0.0047757625579833984\n",
      "Epoch 1, Step 0, Loss 12.6423, Accuracy 0.0000\n",
      "Epoch 1, Step 50, Loss 7.1565, Accuracy 0.0090\n",
      "Epoch 1, Step 100, Loss 6.1277, Accuracy 0.1394\n",
      "Epoch 1: Training Loss 5.8364, Training Accuracy 0.1728, Validation Loss 4.6126\n",
      "Saved checkpoint at epoch 1\n",
      "\n",
      "Start of epoch 2\n",
      "time() = 18.447755098342896\n",
      "Epoch 2, Step 0, Loss 4.7424, Accuracy 0.2773\n",
      "Epoch 2, Step 50, Loss 4.4311, Accuracy 0.3237\n",
      "Epoch 2, Step 100, Loss 4.3059, Accuracy 0.3331\n",
      "Epoch 2: Training Loss 4.2497, Training Accuracy 0.3390, Validation Loss 3.9393\n",
      "Saved checkpoint at epoch 2\n",
      "\n",
      "Start of epoch 3\n",
      "time() = 28.17925500869751\n",
      "Epoch 3, Step 0, Loss 4.1876, Accuracy 0.3193\n",
      "Epoch 3, Step 50, Loss 3.9115, Accuracy 0.3728\n",
      "Epoch 3, Step 100, Loss 3.8145, Accuracy 0.3871\n",
      "Epoch 3: Training Loss 3.7719, Training Accuracy 0.3919, Validation Loss 3.6098\n",
      "Saved checkpoint at epoch 3\n",
      "\n",
      "Start of epoch 4\n",
      "time() = 37.772111892700195\n",
      "Epoch 4, Step 0, Loss 3.7115, Accuracy 0.3782\n",
      "Epoch 4, Step 50, Loss 3.5000, Accuracy 0.4251\n",
      "Epoch 4, Step 100, Loss 3.4105, Accuracy 0.4362\n",
      "Epoch 4: Training Loss 3.3795, Training Accuracy 0.4403, Validation Loss 3.2381\n",
      "Saved checkpoint at epoch 4\n",
      "\n",
      "Start of epoch 5\n",
      "time() = 47.136027812957764\n",
      "Epoch 5, Step 0, Loss 3.2809, Accuracy 0.4160\n",
      "Epoch 5, Step 50, Loss 3.1417, Accuracy 0.4655\n",
      "Epoch 5, Step 100, Loss 3.0640, Accuracy 0.4744\n",
      "Epoch 5: Training Loss 3.0371, Training Accuracy 0.4785, Validation Loss 3.0146\n",
      "Saved checkpoint at epoch 5\n",
      "\n",
      "Start of epoch 6\n",
      "time() = 56.59980750083923\n",
      "Epoch 6, Step 0, Loss 3.0262, Accuracy 0.4538\n",
      "Epoch 6, Step 50, Loss 2.8516, Accuracy 0.4981\n",
      "Epoch 6, Step 100, Loss 2.7975, Accuracy 0.5034\n",
      "Epoch 6: Training Loss 2.7727, Training Accuracy 0.5058, Validation Loss 2.8199\n",
      "Saved checkpoint at epoch 6\n",
      "\n",
      "Start of epoch 7\n",
      "time() = 66.32516026496887\n",
      "Epoch 7, Step 0, Loss 2.8298, Accuracy 0.4664\n",
      "Epoch 7, Step 50, Loss 2.5942, Accuracy 0.5243\n",
      "Epoch 7, Step 100, Loss 2.5414, Accuracy 0.5333\n",
      "Epoch 7: Training Loss 2.5200, Training Accuracy 0.5357, Validation Loss 2.6597\n",
      "Saved checkpoint at epoch 7\n",
      "\n",
      "Start of epoch 8\n",
      "time() = 76.04809141159058\n",
      "Epoch 8, Step 0, Loss 2.4250, Accuracy 0.5420\n",
      "Epoch 8, Step 50, Loss 2.3709, Accuracy 0.5465\n",
      "Epoch 8, Step 100, Loss 2.3177, Accuracy 0.5555\n",
      "Epoch 8: Training Loss 2.3001, Training Accuracy 0.5572, Validation Loss 2.5972\n",
      "Saved checkpoint at epoch 8\n",
      "\n",
      "Start of epoch 9\n",
      "time() = 85.90709972381592\n",
      "Epoch 9, Step 0, Loss 2.3230, Accuracy 0.5126\n",
      "Epoch 9, Step 50, Loss 2.1767, Accuracy 0.5731\n",
      "Epoch 9, Step 100, Loss 2.1224, Accuracy 0.5808\n",
      "Epoch 9: Training Loss 2.1052, Training Accuracy 0.5830, Validation Loss 2.4689\n",
      "Saved checkpoint at epoch 9\n",
      "\n",
      "Start of epoch 10\n",
      "time() = 96.12630438804626\n",
      "Epoch 10, Step 0, Loss 2.0386, Accuracy 0.5756\n",
      "Epoch 10, Step 50, Loss 1.9753, Accuracy 0.5988\n",
      "Epoch 10, Step 100, Loss 1.9257, Accuracy 0.6063\n",
      "Epoch 10: Training Loss 1.9088, Training Accuracy 0.6085, Validation Loss 2.3879\n",
      "Saved checkpoint at epoch 10\n",
      "\n",
      "Start of epoch 11\n",
      "time() = 106.66735243797302\n",
      "Epoch 11, Step 0, Loss 1.9148, Accuracy 0.6008\n",
      "Epoch 11, Step 50, Loss 1.7854, Accuracy 0.6241\n",
      "Epoch 11, Step 100, Loss 1.7453, Accuracy 0.6295\n",
      "Epoch 11: Training Loss 1.7294, Training Accuracy 0.6334, Validation Loss 2.2971\n",
      "Saved checkpoint at epoch 11\n",
      "\n",
      "Start of epoch 12\n",
      "time() = 116.85547542572021\n",
      "Epoch 12, Step 0, Loss 1.7549, Accuracy 0.6176\n",
      "Epoch 12, Step 50, Loss 1.6082, Accuracy 0.6505\n",
      "Epoch 12, Step 100, Loss 1.5728, Accuracy 0.6582\n",
      "Epoch 12: Training Loss 1.5602, Training Accuracy 0.6609, Validation Loss 2.1926\n",
      "Saved checkpoint at epoch 12\n",
      "\n",
      "Start of epoch 13\n",
      "time() = 126.76403737068176\n",
      "Epoch 13, Step 0, Loss 1.5670, Accuracy 0.6513\n",
      "Epoch 13, Step 50, Loss 1.4570, Accuracy 0.6709\n",
      "Epoch 13, Step 100, Loss 1.4269, Accuracy 0.6770\n",
      "Epoch 13: Training Loss 1.4128, Training Accuracy 0.6805, Validation Loss 2.1460\n",
      "Saved checkpoint at epoch 13\n",
      "\n",
      "Start of epoch 14\n",
      "time() = 137.03592801094055\n",
      "Epoch 14, Step 0, Loss 1.3326, Accuracy 0.7059\n",
      "Epoch 14, Step 50, Loss 1.2976, Accuracy 0.6999\n",
      "Epoch 14, Step 100, Loss 1.2775, Accuracy 0.7023\n",
      "Epoch 14: Training Loss 1.2662, Training Accuracy 0.7050, Validation Loss 2.1041\n",
      "Saved checkpoint at epoch 14\n",
      "\n",
      "Start of epoch 15\n",
      "time() = 147.07416200637817\n",
      "Epoch 15, Step 0, Loss 1.2618, Accuracy 0.6555\n",
      "Epoch 15, Step 50, Loss 1.1634, Accuracy 0.7226\n",
      "Epoch 15, Step 100, Loss 1.1365, Accuracy 0.7288\n",
      "Epoch 15: Training Loss 1.1320, Training Accuracy 0.7304, Validation Loss 2.0796\n",
      "Saved checkpoint at epoch 15\n",
      "\n",
      "Start of epoch 16\n",
      "time() = 157.07021307945251\n",
      "Epoch 16, Step 0, Loss 1.1231, Accuracy 0.6933\n",
      "Epoch 16, Step 50, Loss 1.0550, Accuracy 0.7404\n",
      "Epoch 16, Step 100, Loss 1.0257, Accuracy 0.7477\n",
      "Epoch 16: Training Loss 1.0271, Training Accuracy 0.7471, Validation Loss 2.0650\n",
      "Saved checkpoint at epoch 16\n",
      "\n",
      "Start of epoch 17\n",
      "time() = 166.91918444633484\n",
      "Epoch 17, Step 0, Loss 0.9505, Accuracy 0.7521\n",
      "Epoch 17, Step 50, Loss 0.9380, Accuracy 0.7634\n",
      "Epoch 17, Step 100, Loss 0.9167, Accuracy 0.7687\n",
      "Epoch 17: Training Loss 0.9207, Training Accuracy 0.7680, Validation Loss 2.0857\n",
      "Saved checkpoint at epoch 17\n",
      "\n",
      "Start of epoch 18\n",
      "time() = 176.8103950023651\n",
      "Epoch 18, Step 0, Loss 0.9534, Accuracy 0.7773\n",
      "Epoch 18, Step 50, Loss 0.8274, Accuracy 0.7828\n",
      "Epoch 18, Step 100, Loss 0.8044, Accuracy 0.7904\n",
      "Epoch 18: Training Loss 0.8152, Training Accuracy 0.7877, Validation Loss 2.0326\n",
      "Saved checkpoint at epoch 18\n",
      "\n",
      "Start of epoch 19\n",
      "time() = 187.11646246910095\n",
      "Epoch 19, Step 0, Loss 0.8327, Accuracy 0.7857\n",
      "Epoch 19, Step 50, Loss 0.7592, Accuracy 0.7975\n",
      "Epoch 19, Step 100, Loss 0.7426, Accuracy 0.8023\n",
      "Epoch 19: Training Loss 0.7429, Training Accuracy 0.8026, Validation Loss 2.0948\n",
      "Saved checkpoint at epoch 19\n",
      "\n",
      "Start of epoch 20\n",
      "time() = 197.34781432151794\n",
      "Epoch 20, Step 0, Loss 0.7738, Accuracy 0.7773\n",
      "Epoch 20, Step 50, Loss 0.6664, Accuracy 0.8210\n",
      "Epoch 20, Step 100, Loss 0.6575, Accuracy 0.8212\n",
      "Epoch 20: Training Loss 0.6591, Training Accuracy 0.8211, Validation Loss 1.9962\n",
      "Saved checkpoint at epoch 20\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "\n",
    "    print('\\nStart of epoch %d' % (epoch+1))\n",
    "\n",
    "    print(f'time() = {time()-start_time}')\n",
    "\n",
    "    for step, (train_batchX, train_batchY) in enumerate(train_dataset):\n",
    "        encoder_input = train_batchX[:, 1:]\n",
    "        decoder_input = train_batchY[:, :-1]\n",
    "        decoder_output = train_batchY[:, 1:]\n",
    "        #\n",
    "        train_step(encoder_input, decoder_input, decoder_output)\n",
    "        #\n",
    "        if step % 50 == 0:\n",
    "            print(\n",
    "                f'Epoch {epoch+1}, Step {step}, Loss {train_loss.result():.4f}, Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "    for val_batchX, val_batchY in val_dataset:\n",
    "        encoder_input = val_batchX[:, 1:]\n",
    "        decoder_input = val_batchY[:, :-1]\n",
    "        decoder_output = val_batchY[:, 1:]\n",
    "        #\n",
    "        prediction = training_model(\n",
    "            encoder_input, decoder_input, training=False)\n",
    "        loss = loss_fcn(decoder_output, prediction)\n",
    "        val_loss(loss)\n",
    "\n",
    "    print('Epoch %d: Training Loss %.4f, Training Accuracy %.4f, Validation Loss %.4f'\n",
    "          % (epoch+1, train_loss.result(), train_accuracy.result(), val_loss.result()))\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        save_path = ckpt_manager.save()\n",
    "        print('Saved checkpoint at epoch %d' % (epoch + 1))\n",
    "\n",
    "        training_model.save_weights('./metadata/weights/wghts' + str(epoch+1) + '.ckpt')\n",
    "        train_loss_dict[epoch] = train_loss.result()\n",
    "        val_loss_dict[epoch] = val_loss.result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "error",
     "timestamp": 1688862061641,
     "user": {
      "displayName": "ZUOW-ZUN CHEN",
      "userId": "13156931386379130288"
     },
     "user_tz": 420
    },
    "id": "XK7aSy_JCWze",
    "outputId": "120eb8e8-7f84-4313-e000-44f2b5fa5fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 234.21s\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train_loss.pkl', 'wb') as file:\n",
    "    dump(train_loss_dict, file)\n",
    "with open('./data/val_loss.pkl', 'wb') as file:\n",
    "    dump(val_loss_dict, file)\n",
    "print('Total time taken: %.2fs' % (time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPHMuy7elrLF"
   },
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoMxHsaNOHiLR9C8dyuukj",
   "mount_file_id": "1DhBEFRMBO44w8iENdyNEVQsPA_4MYdHZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
