{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5ad08a",
   "metadata": {},
   "source": [
    "# Cleaning the German-English Language Sentence Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e862965",
   "metadata": {},
   "source": [
    "The German-English data set is downloaded from http://www.manythings.org/anki/<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998037fb",
   "metadata": {},
   "source": [
    "This script does the following clean up steps:\n",
    "1. Ignore all chars that cannot be represented in ASCII\n",
    "2. Convert all chars to lowercase \n",
    "3. Remove punctuations \n",
    "4. Remove all non-pretable chars \n",
    "5. Remove none alphabet words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7de4af",
   "metadata": {},
   "source": [
    "This code is refereneced from https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a83bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump \n",
    "from unicodedata import normalize \n",
    "from numpy import array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173ddeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01000cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [l.split('\\t')[0:2] for l in lines]\n",
    "    pairs = pairs[:20000]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857c7b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haltet ihr Tom wirklich für verlässlich?\n",
      "Haltet ihr Tom wirklich für verlässlich?\n",
      "b'Haltet ihr Tom wirklich fur verlasslich?'\n"
     ]
    }
   ],
   "source": [
    "line = \"This is a sentence with non-ASCII characters.\"\n",
    "# Do you know why Tom wasn't there yesterday?\tWeißt du, warum Tom gestern nicht anwesend war? \n",
    "line = \"Weißt du, warum Tom gestern nicht anwesend war?\"\n",
    "# Do you really believe that Tom is reliable?\tHaltet ihr Tom wirklich für verlässlich?\n",
    "line = \"Haltet ihr Tom wirklich für verlässlich?\"\n",
    "print(line)\n",
    "#  Converts all of the characters to their decomposed form\n",
    "normalized_line = normalize('NFD', line)\n",
    "print(normalized_line)\n",
    "# converts the string to ASCII, ignoring any characters that cannot be represented in ASCII\n",
    "encoded_line = normalized_line.encode('ascii', 'ignore')\n",
    "print(encoded_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7421a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "\n",
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"\\#\\$%\\&'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~\\ \\\t\\\n",
      "\\\u000b",
      "\\\f",
      "\n",
      "\n",
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"\\#\\$%\\&'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~\\ \\\t\\\n",
      "\\\u000b",
      "\\\f",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "print(string.printable +'\\n')\n",
    "print(re.escape(string.printable) + '\\n')\n",
    "print('%s' % re.escape(string.printable) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2b5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pairs(pariedLines):\n",
    "    cleaned = list()\n",
    "    # remove non-printable chars\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in pariedLines:\n",
    "        clean_pair = list()\n",
    "        for sentence in pair:\n",
    "            sentence = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
    "            sentence = sentence.decode('UTF-8')\n",
    "            sentence = sentence.split()\n",
    "            sentence = [word.lower() for word in sentence]\n",
    "            sentence = [word.translate(table) for word in sentence]\n",
    "            # remove non-printable chars\n",
    "            sentence = [re_print.sub('', word) for word in sentence]\n",
    "            # Remove words with numbers? how to deal with numbers? \n",
    "            # How to deal with upper case? And , . ? % these signs? \n",
    "            sentence = [word for word in sentence if word.isalpha()] \n",
    "            clean_pair.append(' '.join(sentence))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de69817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print(f'Saved: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ed0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of setences = 20000\n",
      "max_sentence_len = 4, 4\n",
      "Saved: english-german.pkl\n",
      "[she is very wise] -> [sie ist sehr weise]\n",
      "[she is very busy] -> [sie ist sehr beschaftigt]\n",
      "[she is shameless] -> [sie ist schamlos]\n",
      "[she is on a diet] -> [sie ist auf diat]\n",
      "[she is obstinate] -> [sie ist hartnackig]\n",
      "[she is obstinate] -> [sie ist eigensinnig]\n",
      "[she is obstinate] -> [sie ist stur]\n",
      "[she is not young] -> [sie ist nicht jung]\n",
      "[she is not wrong] -> [sie hat nicht unrecht]\n",
      "[she is no beauty] -> [sie ist keine schonheit]\n",
      "[she is mad at me] -> [sie ist wutend auf mich]\n",
      "[she is easygoing] -> [sie ist lassig]\n",
      "[she is beautiful] -> [sie ist schon]\n",
      "[she is an expert] -> [sie ist vom fach]\n",
      "[she is a teacher] -> [sie ist lehrerin]\n",
      "[she is a student] -> [sie ist schulerin]\n",
      "[she is a student] -> [sie ist studentin]\n",
      "[she is ethiopian] -> [sie ist athiopierin]\n",
      "[she insulted him] -> [sie hat ihn beleidigt]\n",
      "[she insulted him] -> [sie beleidigte ihn]\n",
      "[she idolized him] -> [sie hat ihn vergottert]\n",
      "[she idolized him] -> [sie vergotterte ihn]\n",
      "[she has gone out] -> [sie ist ausgegangen]\n",
      "[she has dry hair] -> [sie hat trockene haare]\n",
      "[she has dry hair] -> [sie hat trockenes haar]\n",
      "[she drives a bmw] -> [sie fahrt einen bmw]\n",
      "[she divorced him] -> [sie hat sich von ihm scheiden lassen]\n",
      "[she divorced him] -> [sie lie sich von ihm scheiden]\n",
      "[she disliked him] -> [sie mochte ihn nicht leiden]\n",
      "[she disliked him] -> [sie mochte ihn nicht]\n",
      "[she died in] -> [sie starb]\n",
      "[she died from tb] -> [sie starb an tuberkulose]\n",
      "[she didnt reply] -> [sie antwortete nicht]\n",
      "[she didnt reply] -> [sie hat nicht geantwortet]\n",
      "[she did it again] -> [sie hat es wieder getan]\n",
      "[she did it again] -> [sie hat es schon wieder getan]\n",
      "[she despises him] -> [sie verachtet ihn]\n",
      "[she despised him] -> [sie verachtete ihn]\n",
      "[she defeated him] -> [sie bezwang ihn]\n",
      "[she defeated him] -> [sie hat ihn bezwungen]\n",
      "[she came running] -> [sie kam angelaufen]\n",
      "[she betrayed you] -> [sie verriet dich]\n",
      "[she betrayed you] -> [sie verriet sie]\n",
      "[she betrayed you] -> [sie hat sie verraten]\n",
      "[she betrayed you] -> [sie hat dich verraten]\n",
      "[she began crying] -> [sie begann zu weinen]\n",
      "[she began crying] -> [sie fing an zu weinen]\n",
      "[she became happy] -> [sie wurde glucklich]\n",
      "[she attacked him] -> [sie griff ihn an]\n",
      "[she attacked him] -> [sie hat ihn angegriffen]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    filename = 'deu-eng/deu.txt'\n",
    "    doc = load_doc(filename)\n",
    "    pairs = to_pairs(doc)\n",
    "    cleaned_pairs = clean_pairs(pairs)\n",
    "    print(f'number of setences = {len(cleaned_pairs)}')\n",
    "    print(f'max_sentence_len = {len(cleaned_pairs[-1][0].split())}, {len(cleaned_pairs[-1][1].split())}')        \n",
    "    save_clean_data(cleaned_pairs, 'english-german.pkl')\n",
    "    for i in range(50):\n",
    "        print('[%s] -> [%s]' % (cleaned_pairs[-i-1,0], cleaned_pairs[-i-1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cde1b0",
   "metadata": {},
   "source": [
    "## Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e128648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump \n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69762d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab32736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print(f'Saved: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288f62ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = load_clean_sentences('english-german.pkl')\n",
    "len(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538fd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 1000\n"
     ]
    }
   ],
   "source": [
    "n_sentences = 10000\n",
    "train_test_ratio = 0.9\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "shuffle(dataset)\n",
    "train, test = dataset[ : int(n_sentences*train_test_ratio)], dataset[int(n_sentences*train_test_ratio):]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e708649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german-both.pkl\n",
      "Saved: english-german-train.pkl\n",
      "Saved: english-german-test.pkl\n"
     ]
    }
   ],
   "source": [
    "save_clean_data(dataset, 'english-german-both.pkl')\n",
    "save_clean_data(train, 'english-german-train.pkl')\n",
    "save_clean_data(test, 'english-german-test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
